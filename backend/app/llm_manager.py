import os
import json
import requests
from langchain.memory import ConversationBufferWindowMemory
from langchain.prompts import PromptTemplate
from langchain.chains import ConversationalRetrievalChain
from langchain_chroma import Chroma
from app.ask_api import run_llm

# LLM í˜¸ì¶œì„ /ask APIë¡œë§Œ ìˆ˜í–‰
ASK_API_URL = os.environ.get("ASK_API_URL", "https://youth-chatbot-backend.onrender.com/ask")

# def call_llm_via_ask(prompt: str) -> str:
#     response = requests.post(ASK_API_URL, json={"prompt": prompt})
#     response.raise_for_status()
#     return response.json()["response"]

def call_llm_via_ask(prompt: str) -> str:
    return run_llm(prompt)

# ì„¸ì…˜ë³„ ëŒ€í™” ë©”ëª¨ë¦¬ ì €ì¥ì†Œ (ê°œë°œìš©: ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì™¸ë¶€ DB ì‚¬ìš©)
session_memories = {}

# ì‚¬ìš©ì ì •ë³´ ì €ì¥ì†Œ (ê°œë°œìš©: ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” DB ì‚¬ìš©)
# key: session_id, value: {"user_profile": "ëŒ€í•™ìƒ", "some_other_info": "ê°’"}
user_profiles_db = {}

# User information extraction prompt (English for better performance)
initial_analysis_prompt_template = """
You are an expert policy analyst. Analyze the user's request and extract the following information. Respond in JSON format only:

1. residence: User's residence (e.g., "Seoul", "Gyeonggi", "Other regions")
2. age: User's age (number or age group like "20s", "30s")
3. gender: User's gender ("Male", "Female", "Other", "Not specified")
4. marital_status: Marital status ("Married", "Single", "Not specified")
5. user_profile: Korean summary combining the above info (e.g., "ì„œìš¸ ê±°ì£¼ 20ëŒ€ ë¯¸í˜¼ ì—¬ì„±")
6. policy_area_of_interest: Policy area of interest (e.g., "Housing", "Employment", "Welfare", "Education")
7. specific_keywords: Important keywords from the user's question
8. optimized_search_query: Most effective query for policy search

Output as JSON. Leave empty string if information is not available.

---
User's Request: {user_input}
"""
initial_analysis_prompt = PromptTemplate.from_template(initial_analysis_prompt_template)

# Enhanced QA prompt for better RAG performance
qa_prompt_template = """You are a knowledgeable and empathetic policy assistant specializing in **Korean youth housing policies**. You MUST respond in Korean language only. Provide accurate, comprehensive, and user-centric information based ONLY on the provided policy documents and chat history.

âš ï¸ ë‹¹ì‹ ì€ ì„œìš¸ì‹œ ì²­ë…„ ì£¼ê±° ì •ì±… ì „ìš© AIì…ë‹ˆë‹¤. ë‹¤ìŒ ì§€ì¹¨ì„ ì² ì €íˆ ë”°ë¥´ì„¸ìš”.

---
# USER PROFILE #
User's Profile: {user_profile_data}
---
Chat History:
{chat_history}

---
Retrieved Policy Documents:
{context}

---
User's Question: {question}

---
Instructions for Answer Generation:
1. **Domain Restriction**: Only respond to questions directly related to youth housing policies. If the question is irrelevant (e.g., tax, middle-aged housing, market trends), respond with a friendly message like:  
   "**ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” ì„œìš¸ì‹œ ì²­ë…„ ì£¼ê±° ì •ì±… ì „ìš© AIì…ë‹ˆë‹¤. ê´€ë ¨ëœ ì§ˆë¬¸ë§Œ ë‹µë³€ë“œë¦´ ìˆ˜ ìˆì–´ìš” ğŸ™‡**"
2. **Directness**: Address the user's question directly and clearly.
3. **Accuracy**: Use information strictly from the "Retrieved Policy Documents." Do NOT fabricate or infer missing information.
4. **Completeness**: Include all relevant policy details available in the documents.
5. **User-centric**: Adapt the tone and content to the user's profile (e.g., "ì„œìš¸ ê±°ì£¼ 20ëŒ€ ë¯¸í˜¼ ì—¬ì„±"). If profile is missing or empty, use general language.
6. **Content Selection**: Only include the 2~3 most relevant policies in the main answer. List remaining relevant policies as a **reference list** with brief summaries.
7. **Structure**: Organize content using bullet points or numbered lists for clarity.
8. **Policy Details**: For each main policy in the answer, include:
   - ì •ì±…ëª… (Policy Name)
   - ì„¤ëª… (Description)
   - ì§€ì›ëŒ€ìƒ (Target Beneficiaries)
   - ì‹ ì²­ë°©ë²• (Application Method)
   - ë¬¸ì˜ (Contact Information)
   - ê´€ë ¨ë§í¬ (Related Links) if available
9. **URL Inclusion Format**: If a URL is provided in the policy document, include it using the following format:  
   `<a href="URL" target="_blank">ìì„¸íˆ ë³´ê¸°</a>`  
   Do not fabricate or guess URLs. Only use explicitly provided ones.
10. **Clarity**: Use easy-to-understand and concise Korean. Avoid unnecessary technical jargon.
11. **Language Requirement**: Final response must be written **in Korean only**. Do not use English or any other language.

Provide a helpful, accurate, and strictly domain-specific response. Include the policy URL if it exists in the retrieved documents.
"""

QA_PROMPT = PromptTemplate.from_template(qa_prompt_template)

def get_or_create_memory(session_id):
    """ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒˆë¡œ ìƒì„±"""
    if session_id not in session_memories:
        session_memories[session_id] = ConversationBufferWindowMemory(
            memory_key="chat_history", 
            return_messages=True, 
            k=5
        )
    return session_memories[session_id]

def extract_user_profile(user_message, session_id):
    """ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ í”„ë¡œí•„ ì •ë³´ ì¶”ì¶œ"""
    current_user_profile = user_profiles_db.get(session_id, {}).get("user_profile", "ì •ë³´ ì—†ìŒ")
    
    if current_user_profile == "ì •ë³´ ì—†ìŒ":
        try:
            prompt = initial_analysis_prompt.format(user_input=user_message)
            analysis_response = call_llm_via_ask(prompt)
            initial_info = json.loads(analysis_response)
            extracted_profile = initial_info.get("user_profile")
            if extracted_profile and extracted_profile != "ì •ë³´ ì—†ìŒ":
                user_profiles_db[session_id] = user_profiles_db.get(session_id, {})
                user_profiles_db[session_id]["user_profile"] = extracted_profile
                current_user_profile = extracted_profile
            search_query_from_analysis = initial_info.get("optimized_search_query", user_message)
        except json.JSONDecodeError:
            print("Warning: Initial analysis did not return valid JSON.")
            search_query_from_analysis = user_message
        except Exception as e:
            print(f"Error during initial analysis: {e}")
            search_query_from_analysis = user_message
    else:
        try:
            prompt = initial_analysis_prompt.format(user_input=user_message)
            analysis_response = call_llm_via_ask(prompt)
            initial_info = json.loads(analysis_response)
            search_query_from_analysis = initial_info.get("optimized_search_query", user_message)
        except (json.JSONDecodeError, Exception):
            search_query_from_analysis = user_message
    
    return current_user_profile, search_query_from_analysis

def create_qa_chain(retriever, memory, user_profile, question):
    """ìµœì¢… ì‘ë‹µì„ ìƒì„±í•˜ê³  ë ˆí¼ëŸ°ìŠ¤ ë¬¸ì„œë„ ë¶„ë¦¬í•´ì„œ ë¦¬í„´"""
    # QA í”„ë¡¬í”„íŠ¸ë¥¼ /ask APIë¡œ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„±
    # ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” ì´ë ¥ ë¶ˆëŸ¬ì˜¤ê¸°
    chat_history = memory.load_memory_variables({})["chat_history"]
    
    # ë¦¬íŠ¸ë¦¬ë²„ë¡œ ë¬¸ì„œ ê²€ìƒ‰
    docs = retriever.get_relevant_documents(question) 
    if not docs:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ê´€ë ¨ëœ ì •ì±… ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
    
    # ë²¡í„°DB ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ìƒìœ„ 3ê°œ ë¬¸ì„œ ì„ íƒíˆì—¬ í•„í„°ë§ 
    top3_docs, remaining_docs = filter_documents_by_score(docs, top_n=3)
    context = "\n\n".join([doc.page_content for doc in top3_docs])

    # QA í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = QA_PROMPT.format(
        user_profile_data=user_profile,
        chat_history=chat_history,
        context=context,
        question=question
    )
    answer = call_llm_via_ask(prompt)

    # ë©”ëª¨ë¦¬ì— í˜„ì¬ ì§ˆë¬¸/ì‘ë‹µ ì €ì¥
    memory.save_context({"input": question}, {"output": answer})
    return answer, remaining_docs  # ë ˆí¼ëŸ°ìŠ¤ ë¬¸ì„œë„ ë¶„ë¦¬í•´ì„œ ë¦¬í„´

def get_active_sessions_count():
    """í™œì„± ì„¸ì…˜ ìˆ˜ ë°˜í™˜"""
    return len(session_memories)

def is_housing_policy_question(question: str) -> bool:
    # ì²­ë…„ ì£¼ê±° ì •ì±… ì§ˆë¬¸ íŒë‹¨ (yes/no) 
    # ë²¡í„°DB ì–¸ì–´ì™€ ë§ì¶°ì„œ í•œêµ­ì–´ë¡œ ì‘ì„± ("ì²­ë…„ ì£¼ê±° ì •ì±…", "ì „ì„¸ìê¸ˆ ëŒ€ì¶œ", "ì‹ í˜¼ë¶€ë¶€" ë“± í‚¤ì›Œë“œ ì ‘ê·¼ì„±)
    routing_prompt = """
    // Task
    ì…ë ¥ëœ questionì´ "ì²­ë…„ ì£¼ê±° ì •ì±…"ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.
    answerëŠ” ë°˜ë“œì‹œ "yes" ë˜ëŠ” "no"ë¡œë§Œ í•´ì£¼ì„¸ìš”.

    // Context
    ì²­ë…„ ì£¼ê±° ì •ì±…ì€ ì²­ë…„ì¸µ(ë§Œ 19~39ì„¸)ì„ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” ì£¼ê±° ì§€ì› ì •ì±…ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
    ì˜ˆ: ì²­ë…„ ì „ì„¸ìê¸ˆ ëŒ€ì¶œ, ì²­ë…„ ì„ëŒ€ì£¼íƒ, ì‹ í˜¼ë¶€ë¶€ ì£¼íƒ ë“±

    ---
    question: {question}
    answer:""".strip()

    response = call_llm_via_ask(routing_prompt.format(question=question))
    return response.strip().lower().startswith("yes")

def filter_documents_by_score(docs, top_n=3):
    # ë¬¸ì„œ í•„í„°ë§ í•¨ìˆ˜ (ë²¡í„°DB ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ìƒìœ„ 3ê°œ ë¬¸ì„œ ì„ íƒ)
    sorted_docs = sorted(docs, key=lambda d: -d.metadata.get("score", 0))
    return sorted_docs[:top_n], sorted_docs[top_n:]