import os
import json
import re
import requests
import logging
from langchain.memory import ConversationBufferWindowMemory
from langchain.prompts import PromptTemplate
from langchain.chains import ConversationalRetrievalChain
from langchain_chroma import Chroma
from app.ask_api import run_llm

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# LLM í˜¸ì¶œì„ /ask APIë¡œë§Œ ìˆ˜í–‰
ASK_API_URL = os.environ.get("ASK_API_URL", "https://youth-chatbot-backend.onrender.com/ask")

# def call_llm_via_ask(prompt: str) -> str:
#     response = requests.post(ASK_API_URL, json={"prompt": prompt})
#     response.raise_for_status()
#     return response.json()["response"]

def call_llm_via_ask(prompt: str) -> str:
    return run_llm(prompt)

# ì„¸ì…˜ë³„ ëŒ€í™” ë©”ëª¨ë¦¬ ì €ì¥ì†Œ (ê°œë°œìš©: ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì™¸ë¶€ DB ì‚¬ìš©)
session_memories = {}

# ì‚¬ìš©ì ì •ë³´ ì €ì¥ì†Œ (ê°œë°œìš©: ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” DB ì‚¬ìš©)
# key: session_id, value: {"user_profile": "ëŒ€í•™ìƒ", "some_other_info": "ê°’"}
user_profiles_db = {}

# User information extraction prompt (English for better performance)
initial_analysis_prompt_template = """
You are an expert policy analyst. Analyze the user's request and extract the following information. Respond in JSON format only:

1. residence: User's residence (e.g., "Seoul", "Gyeonggi", "Other regions")
2. age: User's age (number or age group like "20s", "30s")
3. gender: User's gender ("Male", "Female", "Other", "Not specified")
4. marital_status: Marital status ("Married", "Single", "Not specified")
5. user_profile: Korean summary combining the above info (e.g., "ì„œìš¸ ê±°ì£¼ 20ëŒ€ ë¯¸í˜¼ ì—¬ì„±")
6. policy_area_of_interest: Policy area of interest (e.g., "Housing", "Employment", "Welfare", "Education")
7. specific_keywords: Important keywords from the user's question
8. optimized_search_query: Most effective query for policy search

Output as JSON. Leave empty string if information is not available.

---
User's Request: {user_input}
"""
initial_analysis_prompt = PromptTemplate.from_template(initial_analysis_prompt_template)

# Enhanced QA prompt for better RAG performance
qa_prompt_template = """You are a knowledgeable and empathetic policy assistant specializing in **Korean youth housing policies**. You MUST respond in Korean language only. Provide accurate, comprehensive, and user-centric information based ONLY on the provided policy documents and chat history.

âš ï¸ ë‹¹ì‹ ì€ ì„œìš¸ì‹œ ì²­ë…„ ì£¼ê±° ì •ì±… ì „ìš© AIì…ë‹ˆë‹¤. ë‹¤ìŒ ì§€ì¹¨ì„ ì² ì €íˆ ë”°ë¥´ì„¸ìš”.

---
# USER PROFILE #
User's Profile: {user_profile_data}
---
Chat History:
{chat_history}

---
Retrieved Policy Documents:
{context}

---
User's Original Question: {question}

---
User's Optimized Search Query: {search_query}

---
Instructions for Answer Generation:
1. **Directness**: Address the user's question directly and clearly.
2. **Accuracy**: Base your response primarily on the "Retrieved Policy Documents." If they do not provide a direct match, you may recommend the most contextually relevant policies from within them.
3. **Completeness**: Include all relevant policy details available in the documents.
4. **User-centric**: Adapt the tone and content to the user's profile (e.g., "ì„œìš¸ ê±°ì£¼ 20ëŒ€ ë¯¸í˜¼ ì—¬ì„±"). If profile is missing or empty, use general language.
5. **Content Selection**: Only include the 2~3 most relevant policies in the main answer. List remaining relevant policies as a **reference list** with brief summaries if it exists.
6. **Structure**: Organize content using bullet points or numbered lists for clarity.
7. **Policy Details**: For each main policy in the answer, include:
   - ì •ì±…ëª… (Policy Name)
   - ì„¤ëª… (Description)
   - ì§€ì›ëŒ€ìƒ (Target Beneficiaries)
   - ì‹ ì²­ë°©ë²• (Application Method)
   - ë¬¸ì˜ (Contact Information)
   - ê´€ë ¨ë§í¬ (Related Links) if available
8. **URL Inclusion Format**: If a URL is provided in the policy document, include it using the following format:  
   `<a href="URL" target="_blank">ìì„¸íˆ ë³´ê¸°</a>`  
   Do not fabricate or guess URLs. Only use explicitly provided ones.
9. **Clarity**: Use easy-to-understand and concise Korean. Avoid unnecessary technical jargon.
10. **Language Requirement**: Final response must be written **in Korean only**. Do not use English or any other language.
11. **Domain Restriction**: Only respond to questions directly related to youth housing policies. If the question is irrelevant (e.g., tax, middle-aged housing, market trends), respond with a friendly message like:  
   "**ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” ì„œìš¸ì‹œ ì²­ë…„ ì£¼ê±° ì •ì±… ì „ìš© AIì…ë‹ˆë‹¤. ê´€ë ¨ëœ ì§ˆë¬¸ë§Œ ë‹µë³€ë“œë¦´ ìˆ˜ ìˆì–´ìš” ğŸ™‡**"
12. **Icons**: Please include appropriate icons (e.g., âœ…, ğŸ“Œ, âš ï¸) to enhance clarity and readability.
13. **Personalization**: Make sure your response is accurate and helpful, accurate, and also personalize the explanation based on the user's context. Include the policy URL if it exists in the retrieved documents.
14. **Tone**: Use a warm, empathetic, and reliable tone. Acknowledge the user's situation when appropriate.
15. **Engagement**: You can think through when to be warm and vibrant and can sound empathetic and nonjudgmental but don't show your thinking. When appropriate, end the response with a question or statement to encourage further conversation.
16. Greeting & Empathy Introduction:
Begin your response with a friendly and empathetic greeting when appropriate. Use the following format:

"ì•ˆë…•í•˜ì„¸ìš”! [Userâ€™s situation]ì„ ê³ ë¯¼í•˜ê³  ê³„ì‹œëŠ”êµ°ìš”."

This helps establish trust and warmth before introducing relevant policy information.
"""


QA_PROMPT = PromptTemplate.from_template(qa_prompt_template)

def get_or_create_memory(session_id):
    """ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒˆë¡œ ìƒì„±"""
    if session_id not in session_memories:
        session_memories[session_id] = ConversationBufferWindowMemory(
            memory_key="chat_history", 
            return_messages=True, 
            k=5
        )
    return session_memories[session_id]

def extract_user_profile(user_message, session_id):
    """ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ í”„ë¡œí•„ ì •ë³´ ì¶”ì¶œ"""
    current_user_profile = user_profiles_db.get(session_id, {}).get("user_profile", "ì •ë³´ ì—†ìŒ")
    
    if current_user_profile == "ì •ë³´ ì—†ìŒ":
        try:
            prompt = initial_analysis_prompt.format(user_input=user_message)
            analysis_response = call_llm_via_ask(prompt)
            initial_info = json.loads(analysis_response)
            extracted_profile = initial_info.get("user_profile")
            if extracted_profile and extracted_profile != "ì •ë³´ ì—†ìŒ":
                user_profiles_db[session_id] = user_profiles_db.get(session_id, {})
                user_profiles_db[session_id]["user_profile"] = extracted_profile
                current_user_profile = extracted_profile
            search_query_from_analysis = initial_info.get("optimized_search_query", user_message)
        except json.JSONDecodeError:
            print("Warning: Initial analysis did not return valid JSON.")
            search_query_from_analysis = user_message
        except Exception as e:
            print(f"Error during initial analysis: {e}")
            search_query_from_analysis = user_message
    else:
        try:
            prompt = initial_analysis_prompt.format(user_input=user_message)
            analysis_response = call_llm_via_ask(prompt)
            initial_info = json.loads(analysis_response)
            search_query_from_analysis = initial_info.get("optimized_search_query", user_message)
        except (json.JSONDecodeError, Exception):
            search_query_from_analysis = user_message
    
    return current_user_profile, search_query_from_analysis

def create_fallback_answer(user_profile, chat_history, question, search_query):
    logger.warning(f"[Fallback] Fallback ë‹µë³€ ìƒì„± ì‹œì‘ - ì§ˆë¬¸: '{question}', ê²€ìƒ‰ì¿¼ë¦¬: '{search_query}'")
    
    # return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ê´€ë ¨ëœ ì •ì±… ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
    # fallback í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    fallback_prompt_template = """
            ë„ˆëŠ” 'ì„œìš¸ì‹œ ì²­ë…„ ì£¼ê±° ì •ì±… ì „ë¬¸ AI'ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê²Œ ëŒ€ì‘ë˜ëŠ” ì •ì±… ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆì§€ë§Œ, ì‚¬ìš©ìì˜ ìƒí™©ì´ ì²­ë…„ ì£¼ê±°ì™€ ê´€ë ¨ ìˆë‹¤ê³  íŒë‹¨ëœë‹¤ë©´ ì•„ë˜ ì§€ì¹¨ì— ë”°ë¼ ìœ ì‚¬ ì •ì±…ì„ ì œì•ˆí•´ì¤˜.

            ---
            # USER PROFILE #
            {user_profile_data}

            # USER'S QUESTION #
            {question}

            # CHAT HISTORY #
            {chat_history}
            
            # SEARCH QUERY #
            {search_query}

            **ë‹µë³€ êµ¬ì¡°:**
            1. **ê³µê°ì  ì¸ì‚¬ë§**: ì‚¬ìš©ìì˜ ìƒí™©ì— ê³µê°í•˜ëŠ” ë”°ëœ»í•œ ì¸ì‚¬ë§
            2. **ì •ì±… ì œì•ˆ**: ìœ ì‚¬í•œ ì •ì±… 1-2ê°œë¥¼ ìƒì„¸íˆ ì†Œê°œ
            3. **ëŒ€í™” ë§ˆë¬´ë¦¬**: ì¶”ê°€ ì§ˆë¬¸ì„ ìœ ë„í•˜ëŠ” ë§ˆë¬´ë¦¬
            4. ì‚¬ìš©ìì˜ ìƒí™©ì— ê³µê°í•˜ëŠ” ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ë˜, ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆê²Œ ë§í•´ì¤˜.
            5. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ë‹µí•˜ê³ , ì˜ì–´ëŠ” í¬í•¨í•˜ì§€ ë§ˆ.
            6. í•˜ë‚˜ì˜ ì •ì±…ë§Œ ì¶”ì²œí•´ë„ ë˜ì§€ë§Œ, ìµœëŒ€ 2~3ê°œê¹Œì§€ í¬í•¨í•  ìˆ˜ ìˆì–´.
            
            **ìƒì„¸ ì§€ì¹¨:**
            1. **ê³µê°ì  ì¸ì‚¬ë§**: "ì•ˆë…•í•˜ì„¸ìš”! [ì‚¬ìš©ì ìƒí™©]ì„ ê³ ë¯¼í•˜ê³  ê³„ì‹œëŠ”êµ°ìš”." í˜•ì‹ìœ¼ë¡œ ì‹œì‘
            2. **ì •ì±… ì†Œê°œ**: ê° ì •ì±…ì„ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”:
               - âœ… ì •ì±…ëª…
               - ğŸ“ ì„¤ëª…: ì •ì±…ì˜ í•µì‹¬ ë‚´ìš©
               - ğŸ¯ ì§€ì›ëŒ€ìƒ: êµ¬ì²´ì ì¸ ìê²© ìš”ê±´
               - ğŸ’¡ ì‹ ì²­ë°©ë²•: ë‹¨ê³„ë³„ ì‹ ì²­ ì ˆì°¨
               - ğŸ“ ë¬¸ì˜: ì—°ë½ì²˜ ì •ë³´
               - ğŸ”— ê´€ë ¨ë§í¬: `<a href="URL" target="_blank">ìì„¸íˆ ë³´ê¸°</a>` í˜•ì‹
            3. **ì´ëª¨ì§€ í™œìš©**: âœ…ğŸ“ğŸ¯ğŸ’¡ğŸ“ğŸ”— ë“± ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©
            4. **ëŒ€í™” ë§ˆë¬´ë¦¬**: "í˜¹ì‹œ [ê´€ë ¨ ì£¼ì œ]ì— ê¶ê¸ˆí•œ ì ì´ë‚˜ ë‹¤ë¥¸ ê³ ë¯¼ì´ ìˆìœ¼ì‹ ê°€ìš”? í¸í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”!" í˜•ì‹ìœ¼ë¡œ ë§ˆë¬´ë¦¬
            5. **ì¹œê·¼í•¨**: ì „ë¬¸ì ì´ë©´ì„œë„ ë”°ëœ»í•˜ê³  ê³µê°í•˜ëŠ” í†¤ ìœ ì§€
            6. **ê°„ê²°ì„±**: í•µì‹¬ ì •ë³´ ìœ„ì£¼ë¡œ ëª…í™•í•˜ê²Œ ì „ë‹¬


            ì¶œë ¥ì€ ì‘ë‹µ ë³¸ë¬¸ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„±í•´ì¤˜. ë©”íƒ€ ì •ë³´ë‚˜ JSON ì—†ì´ ëŒ€í™”ì²´ë¡œ ì‘ì„±í•´.
        """
    fallback_prompt = fallback_prompt_template.format(
        user_profile_data=user_profile,
        chat_history=chat_history,
        question=question,
        search_query=search_query
    )
    fallback_answer = call_llm_via_ask(fallback_prompt)
    
    logger.info(f"[Fallback] Fallback ë‹µë³€ ìƒì„± ì™„ë£Œ (ì‘ë‹µ ê¸¸ì´: {len(fallback_answer)}ì)")
    logger.info(f"[Fallback] Fallback ë‹µë³€ ë‚´ìš©: {fallback_answer[:200]}...")
    
    return fallback_answer, []


def create_qa_chain(retriever, memory, user_profile, question, search_query):
    """ìµœì¢… ì‘ë‹µì„ ìƒì„±í•˜ê³  ë ˆí¼ëŸ°ìŠ¤ ë¬¸ì„œë„ ë¶„ë¦¬í•´ì„œ ë¦¬í„´"""
    # QA í”„ë¡¬í”„íŠ¸ë¥¼ /ask APIë¡œ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„±
    # ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” ì´ë ¥ ë¶ˆëŸ¬ì˜¤ê¸°
    chat_history = memory.load_memory_variables({})["chat_history"]
    
    # ë¦¬íŠ¸ë¦¬ë²„ë¡œ ë¬¸ì„œ ê²€ìƒ‰ - search_queryë¥¼ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ question ì‚¬ìš©
    search_terms = search_query if search_query and search_query.strip() else question
    logger.info(f"[QA Chain] ê²€ìƒ‰ ì¿¼ë¦¬: '{search_terms}' (ì›ë³¸ ì§ˆë¬¸: '{question}')")
    
    docs = retriever.get_relevant_documents(search_terms)
    logger.info(f"[QA Chain] ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")
    
    if not docs:
        logger.warning(f"[QA Chain] ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨ -> Fallbackìœ¼ë¡œ ì „í™˜")
        return create_fallback_answer(user_profile, chat_history, question, search_query)
    
    # ë²¡í„°DB ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ìƒìœ„ 3ê°œ ë¬¸ì„œ ì„ íƒíˆì—¬ í•„í„°ë§ 
    top3_docs, remaining_docs = filter_documents_by_score(docs, top_n=3)
    context = "\n\n".join([doc.page_content for doc in top3_docs])
    
    logger.info(f"[QA Chain] ìƒìœ„ ë¬¸ì„œ ìˆ˜: {len(top3_docs)}, ë‚˜ë¨¸ì§€ ë¬¸ì„œ ìˆ˜: {len(remaining_docs)}")

    # QA í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = QA_PROMPT.format(
        user_profile_data=user_profile,
        chat_history=chat_history,
        context=context,
        question=question,
        search_query=search_query
    )
    answer = call_llm_via_ask(prompt)
    
    logger.info(f"[QA Chain] ì •ìƒ ì‘ë‹µ ìƒì„± ì™„ë£Œ (ì‘ë‹µ ê¸¸ì´: {len(answer)}ì)")

    # ë©”ëª¨ë¦¬ì— í˜„ì¬ ì§ˆë¬¸/ì‘ë‹µ ì €ì¥
    memory.save_context({"input": question}, {"output": answer})
    
    remaining_list = []
    for doc in remaining_docs:
        # ì •ì±…ëª… ì¶”ì¶œ
        match = re.search(r'ì •ì±…ëª…:([^\n]+)', doc.page_content)
        title = match.group(1).strip() if match else "ì •ì±… ì •ë³´"
        # ê´€ë ¨ë§í¬ ì¶”ì¶œ
        url_match = re.search(r'ê´€ë ¨ë§í¬: *([^\n\s]+)', doc.page_content)
        url = url_match.group(1).strip() if url_match else ""
        remaining_list.append({
            "title": title,
            "url": url
        })
        
    logger.info(f"[QA Chain] remaining_list: {remaining_list}")

    return answer, remaining_list  # ë ˆí¼ëŸ°ìŠ¤ ë¬¸ì„œë„ ë¶„ë¦¬í•´ì„œ ë¦¬í„´

def get_active_sessions_count():
    """í™œì„± ì„¸ì…˜ ìˆ˜ ë°˜í™˜"""
    return len(session_memories)

def is_housing_policy_question(question: str) -> bool:
    # ì£¼ê±° ì •ì±… ì§ˆë¬¸ íŒë‹¨ (yes/no) 
    # ë²¡í„°DB ì–¸ì–´ì™€ ë§ì¶°ì„œ í•œêµ­ì–´ë¡œ ì‘ì„± ("ì£¼ê±° ì •ì±…", "ì „ì„¸ìê¸ˆ ëŒ€ì¶œ", "ì‹ í˜¼ë¶€ë¶€" ë“± í‚¤ì›Œë“œ ì ‘ê·¼ì„±)
    routing_prompt = """
    ì•„ë˜ ì§ˆë¬¸ì´ ì£¼ê±° ì •ì±…ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ yes ë˜ëŠ” noë¡œë§Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.

    [ì£¼ê±° ì •ì±… ì •ì˜]
    ì£¼ê±° ì •ì±…ì€ ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ì£¼ê±° ê´€ë ¨ ì§€ì›ì„ í¬í•¨í•©ë‹ˆë‹¤:
    - ì „ì„¸ìê¸ˆ, ì›”ì„¸ ì§€ì›
    - ì„ëŒ€ì£¼íƒ ê³µê¸‰
    - ìë¦½ ì§€ì› ì£¼ê±°
    - ì‹ í˜¼ë¶€ë¶€, ì‚¬íšŒì´ˆë…„ìƒ ëŒ€ìƒ ì£¼íƒ ì§€ì›
    - ì£¼ê±°ê¸‰ì—¬, ì´ì‚¬ë¹„, ë³´ì¦ê¸ˆ ë“± ì£¼ê±°ë¹„ìš© ë¶€ë‹´ ì™„í™”

    [ì˜ˆì‹œ]
    Q: ì „ì„¸ë³´ì¦ê¸ˆì„ ëª» ëŒë ¤ë°›ì•˜ì–´ìš” â†’ yes  
    Q: ìì·¨í•˜ê³  ì‹¶ì€ë° ëˆì´ ì—†ì–´ìš” â†’ yes  
    Q: 20ëŒ€ ì²­ë…„ ì£¼ê±° ì§€ì›ì •ì±…ì´ ìˆë‚˜ìš”? â†’ yes  
    Q: ì‹ í˜¼ë¶€ë¶€ë¥¼ ìœ„í•œ ì£¼íƒ ì •ì±…ì€ ì–´ë–¤ ê²Œ ìˆì–´ìš”? â†’ yes  
    Q: ë¶€ë™ì‚° ì‹œì¥ ì „ë§ì€? â†’ no  
    Q: ì¢…í•©ë¶€ë™ì‚°ì„¸ ì¤„ì¼ ìˆ˜ ìˆë‚˜ìš”? â†’ no  
    Q: ì¤‘ì¥ë…„ ì£¼ê±°ë³µì§€ì— ëŒ€í•´ ì•Œë ¤ì¤˜ â†’ no  

    ---
    Q: {question}
    A:
    """.strip()

    response = call_llm_via_ask(routing_prompt.format(question=question))
    return response.strip().lower().startswith("yes")

def filter_documents_by_score(docs, top_n=3):
    # ë¬¸ì„œ í•„í„°ë§ í•¨ìˆ˜ (ë²¡í„°DB ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ìƒìœ„ 3ê°œ ë¬¸ì„œ ì„ íƒ)
    sorted_docs = sorted(docs, key=lambda d: -d.metadata.get("score", 0))
    return sorted_docs[:top_n], sorted_docs[top_n:]